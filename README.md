# Modelling Minds 2025

Welcome to **Modelling Minds**, a machine learning hackathon organized by **VIT Mathematical Association (VITMAS)**.

## Event Details
**Date:** September 27-28, 2025  
**Duration:** 48 hours  
**Organizer:** VIT Mathematical Association (VITMAS)  
**Format:** Team-based competition

## Competition Overview
Modelling Minds challenges participants to solve real-world problems using cutting-edge machine learning techniques across three specialized tracks. Each track focuses on different aspects of AI and data science, offering diverse opportunities to showcase your skills.

## Competition Tracks

### 1. Classification Track
Dive into the world of pattern recognition and categorical prediction with these challenging problems:

#### Problem Statements:
- **Canes Et Feles** - Advanced classification challenge
- **Codex of Conundrums** - Complex categorical analysis

### 2. Forecasting Track
Predict the future with time-series analysis and predictive modeling:

#### Problem Statements:
- **Contours in Time** - Temporal pattern analysis
- **Bullish Horizons** - Financial forecasting challenge

### 3. X-AI Track
Explore explainable AI and cutting-edge machine learning applications:

#### Problem Statements:
- **Atlas of Expressions** - AI interpretability challenge
- **Resilient Minds** - Robust AI systems development

## Repository Structure

```
modelling-minds-hackathon/
├── README.md
├── Classification/
│   ├── Canes-Et-Feles/
│   │   ├── README.md
│   │   ├── submission_format.md
│   └── Codex-of-Conundrums/
│       ├── README.md
│       ├── submission_format.md
├── Forecasting/
│   ├── Contours-in-Time/
│   │   ├── README.md
│   │   ├── submission_format.md
│   └── Bullish-Horizons/
│       ├── README.md
│       ├── submission_format.md
└── X-AI/
    ├── Atlas-of-Expressions/
    │   ├── README.md
    │   ├── submission_format.md
    └── Resilient-Minds/
        ├── README.md
        ├── submission_format.md
```

## Getting Started

1. **Choose Your Track**: Select the track that aligns with your interests and expertise
2. **Read Problem Statements**: Navigate to the respective folder and read the detailed README for each problem
3. **Review Data**: Examine the provided datasets and understand the data structure
4. **Check Submission Format**: Follow the specified submission guidelines for your chosen problem
5. **Understand Evaluation**: Review the evaluation metrics to optimize your approach

## Submission Guidelines

Each problem statement has its own specific submission requirements. Please refer to the `submission_format.md` file in each problem's directory for detailed instructions including:

- File naming conventions
- Required file formats
- Documentation requirements
- Code submission guidelines

## Evaluation

Evaluation criteria vary by track and problem statement. Each problem directory contains an `evaluation_metrics.md` file with:

- Primary evaluation metrics
- Secondary metrics (if applicable)
- Scoring methodology
- Ranking criteria

## Competition Rules and Guidelines

### General Conduct
- **Maintain Professionalism**: All participants are expected to conduct themselves with civility and respect throughout the competition
- **Academic Integrity**: While collaboration within teams is encouraged, plagiarism from external sources is strictly prohibited
- **Data Usage**: Participants may only use the provided datasets. External data sources are not permitted unless explicitly stated

### Technical Guidelines
- **Large Language Model Usage**: While the use of LLMs (ChatGPT, Claude, etc.) for assistance is discouraged, it is not strictly forbidden. However, over-reliance on such tools may impact the originality assessment of your solution
- **Dataset Security**: Attempting reverse searches or external sourcing of the competition datasets will not yield results and is discouraged
- **Code Originality**: Solutions should demonstrate your understanding and implementation skills rather than copied code snippets

### Evaluation Process
- **Judging Panel**: Solutions will be evaluated by a panel of expert judges
- **Oral Defense**: Teams may be called for questioning sessions where judges will assess understanding and approach
- **Multiple Evaluation Criteria**: Each problem will be assessed on various dimensions (detailed in respective README files)

## Evaluation Criteria

All solutions will be evaluated across multiple dimensions. Specific weightings and metrics are detailed in each problem's README, but the general evaluation framework follows this structure:

| **Evaluation Category** | **Criteria** | **Weight** |
|-------------------------|--------------|------------|
| **Technical Factors** | Model Performance | 40% |
| | Analysis of Data | 10% |
| | Feature Engineering | 10% |
| | Model Selection | 10% |
| **Innovation & Approach** | Uniqueness of Solution | 15% |
| | Technical Innovation | 10% |
| | Problem Understanding | 5% |
| **Documentation & Presentation** | Code Quality | 8% |
| | Documentation | 7% |
| | Defense | 10% |

**Note:** Individual problem statements may have slight variations in weightings based on the specific nature of the challenge. Refer to the respective problem README files for exact evaluation metrics and any track-specific modifications to this framework.

## Tips for Success

- **Start Early**: Begin with thorough data exploration and understanding
- **Read Thoroughly**: Pay close attention to problem statements and evaluation criteria
- **Document Well**: Clear documentation and reasoning can significantly impact your score
- **Test Rigorously**: Ensure your solution works with the provided test cases
- **Focus on Understanding**: Prioritize deep understanding over quick fixes
- **Prepare for Questions**: Be ready to explain your approach, assumptions, and design choices

## Support & Contact

For technical queries and clarifications:
- Check the individual problem README files first
- Reach out to VITMAS organizers through official channels
- Join the hackathon Discord/Slack for real-time support

## Awards & Recognition

Winners from each track will be recognized and awarded. Stay tuned for announcement of prizes and recognition categories.

---

## A Message from VITMAS

Welcome to Modelling Minds, a journey that extends far beyond algorithms and accuracy scores. This hackathon represents more than a competition—it's an opportunity to explore the fascinating intersection of mathematics, technology, and human ingenuity.

Over the next 48 hours, you'll encounter challenges that mirror real-world complexities, from understanding patterns in data to forecasting future trends and building AI systems that can explain their reasoning. Each problem has been carefully crafted to push the boundaries of your analytical thinking and technical expertise.

Remember that the most profound insights often emerge not from the final model, but from the journey of exploration, experimentation, and discovery. The questions you ask of your data, the assumptions you challenge, and the creative solutions you devise are what truly define excellence in data science.

We encourage you to embrace both success and failure as learning opportunities. Some of the most innovative breakthroughs in machine learning have come from approaches that initially seemed unconventional. Don't be afraid to think differently, question established norms, and propose novel solutions.

As you embark on this intellectual adventure, carry with you the spirit of curiosity that drives all great mathematical and scientific endeavors. Whether you're working on classification challenges, time-series forecasting, or explainable AI, remember that behind every dataset lies a story waiting to be told, and behind every algorithm lies the potential to make a meaningful impact.

We wish you not just success in the competition, but also the joy of discovery and the satisfaction that comes from pushing the boundaries of what's possible with data and mathematics.

**May your models be robust, your insights be profound, and your journey be transformative.**

*— The VIT Mathematical Association (VITMAS) Team*
